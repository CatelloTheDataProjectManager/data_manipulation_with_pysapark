{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkApplication\n",
    "spark = SparkSession.builder.appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ff36abda06ff:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbbfda63510>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark details\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file with header\n",
    "df = spark.read.option('header', 'true').csv('heart.csv')\n",
    "\n",
    "# Specify the schema\n",
    "schema = 'Age INTEGER, Sex STRING, ChestPainType STRING'\n",
    "df = spark.read.csv('heart.csv', schema=schema, header=True)\n",
    "\n",
    "# Infer the schema\n",
    "# df = spark.read.csv('heart.csv', inferSchema=True, header=True)\n",
    "\n",
    "# Replace null values with 'NA'\n",
    "df = spark.read.csv('heart.csv', nullValue='NA')\n",
    "\n",
    "# Save the DataFrame as a CSV file (overwrite mode)\n",
    "df.write.format(\"csv\").mode(\"overwrite\").save(\"heart_save.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------------+\n",
      "|Age|Sex|ChestPainType|\n",
      "+---+---+-------------+\n",
      "| 40|  M|          ATA|\n",
      "| 49|  F|          NAP|\n",
      "| 37|  M|          ATA|\n",
      "+---+---+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('header', 'true').csv('heart.csv')\n",
    "df = df.select(\"Age\", \"Sex\", \"ChestPainType\")\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "918"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be avare with a large amount of data !\n",
    "# df.cache()\n",
    "# df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PySpark DataFrame to Pandas DataFrame\n",
    "pd_df = df.toPandas()\n",
    "# convert it back\n",
    "spark_df = spark.createDataFrame(pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Age='40', Sex='M', ChestPainType='ATA'),\n",
       " Row(Age='49', Sex='F', ChestPainType='NAP'),\n",
       " Row(Age='37', Sex='M', ChestPainType='ATA')]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- ChestPainType: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# type os columns\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', 'string'), ('Sex', 'string'), ('ChestPainType', 'string')]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast a column from one type to other\n",
    "from pyspark.sql.types import FloatType\n",
    "df = df.withColumn(\"Age\",df.Age.cast(FloatType()))\n",
    "df = df.withColumn(\"RestingBP\",df.Age.cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|               Age|         RestingBP|\n",
      "+-------+------------------+------------------+\n",
      "|  count|               918|               918|\n",
      "|   mean|53.510893246187365|53.510893246187365|\n",
      "| stddev|  9.43261650673202|  9.43261650673202|\n",
      "|    min|              28.0|              28.0|\n",
      "|    max|              77.0|              77.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute summery statistics\n",
    "df.select(['Age','RestingBP']).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column or replace existing one\n",
    "AgeFixed = df['Age'] + 1\n",
    "df = df.withColumn('AgeFixed', AgeFixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|          AgeFixed|               Age|\n",
      "+-------+------------------+------------------+\n",
      "|  count|               918|               918|\n",
      "|   mean|54.510893246187365|53.510893246187365|\n",
      "| stddev|  9.43261650673202|  9.43261650673202|\n",
      "|    min|              29.0|              28.0|\n",
      "|    max|              78.0|              77.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['AgeFixed','Age']).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------------+---------+\n",
      "| Age|Sex|ChestPainType|RestingBP|\n",
      "+----+---+-------------+---------+\n",
      "|40.0|  M|          ATA|     40.0|\n",
      "+----+---+-------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove columns\n",
    "df.drop('AgeFixed').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|40.0|\n",
      "+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename a column\n",
    "df.withColumnRenamed('Age','age').select('age').show(1)\n",
    "# renaming mulitple columns with a loop\n",
    "name_pairs = [('Age','age'),('Sex','sex')]\n",
    "for old_name, new_name in name_pairs:\n",
    "    df = df.withColumnRenamed(old_name,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "| age|sex|\n",
      "+----+---+\n",
      "|40.0|  M|\n",
      "+----+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['age','sex']).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA\n",
    "df = df.na.drop()\n",
    "df.count()\n",
    "# drop all NA\n",
    "df = df.na.drop(how='all')\n",
    "# drop all rows where more at least 2 values are NOT NA\n",
    "df = df.na.drop(thresh=2)\n",
    "# drop all rows where any value at specific columns are NAs.\n",
    "df = df.na.drop(how='any', subset=['age','sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation\n",
    "df = df.na.fill(value='?',subset=['sex'])\n",
    "# replace NAs with mean of column\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imptr = Imputer(inputCols=['age','RestingBP'],\n",
    "                outputCols=['age','RestingBP']).setStrategy('mean')\n",
    "\n",
    "df = imptr.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: float, sex: string, ChestPainType: string, RestingBP: float, AgeFixed: float]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering\n",
    "df.filter('age > 18')\n",
    "df.where('age > 18') # or df.where(df['age'] > 18)\n",
    "\n",
    "# filtering with condition\n",
    "df.where((df['age'] > 18) | (df['ChestPainType'] == 'ATA'))\n",
    "df.filter(~(df['ChestPainType'] == 'ATA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------------+---------+--------+\n",
      "| age|sex|ChestPainType|RestingBP|AgeFixed|\n",
      "+----+---+-------------+---------+--------+\n",
      "|40.0|  M|          ATA|     40.0|    41.0|\n",
      "|49.0|  F|          NAP|     49.0|    50.0|\n",
      "|37.0|  M|          ATA|     37.0|    38.0|\n",
      "|48.0|  F|          ASY|     48.0|    49.0|\n",
      "|54.0|  M|          NAP|     54.0|    55.0|\n",
      "|39.0|  M|          NAP|     39.0|    40.0|\n",
      "|45.0|  F|          ATA|     45.0|    46.0|\n",
      "|54.0|  M|          ATA|     54.0|    55.0|\n",
      "|37.0|  M|          ASY|     37.0|    38.0|\n",
      "|48.0|  F|          ATA|     48.0|    49.0|\n",
      "|37.0|  F|          NAP|     37.0|    38.0|\n",
      "|58.0|  M|          ATA|     58.0|    59.0|\n",
      "|39.0|  M|          ATA|     39.0|    40.0|\n",
      "|49.0|  M|          ASY|     49.0|    50.0|\n",
      "|42.0|  F|          NAP|     42.0|    43.0|\n",
      "|54.0|  F|          ATA|     54.0|    55.0|\n",
      "|38.0|  M|          ASY|     38.0|    39.0|\n",
      "|43.0|  F|          ATA|     43.0|    44.0|\n",
      "|60.0|  M|          ASY|     60.0|    61.0|\n",
      "|36.0|  M|          ATA|     36.0|    37.0|\n",
      "+----+---+-------------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('age > 18').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|new_col|\n",
      "+-------+\n",
      "|   48.2|\n",
      "|   59.0|\n",
      "|   44.6|\n",
      "+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate a string expression into command\n",
    "from pyspark.sql.functions import expr\n",
    "exp = 'age + 0.2 * AgeFixed'\n",
    "df.withColumn('new_col', expr(exp)).select('new_col').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------------+---------+--------+\n",
      "| age|sex|ChestPainType|RestingBP|AgeFixed|\n",
      "+----+---+-------------+---------+--------+\n",
      "|40.0|  M|          ATA|     40.0|    41.0|\n",
      "|49.0|  F|          NAP|     49.0|    50.0|\n",
      "|37.0|  M|          ATA|     37.0|    38.0|\n",
      "|48.0|  F|          ASY|     48.0|    49.0|\n",
      "|54.0|  M|          NAP|     54.0|    55.0|\n",
      "|39.0|  M|          NAP|     39.0|    40.0|\n",
      "|45.0|  F|          ATA|     45.0|    46.0|\n",
      "|54.0|  M|          ATA|     54.0|    55.0|\n",
      "|37.0|  M|          ASY|     37.0|    38.0|\n",
      "|48.0|  F|          ATA|     48.0|    49.0|\n",
      "|37.0|  F|          NAP|     37.0|    38.0|\n",
      "|58.0|  M|          ATA|     58.0|    59.0|\n",
      "|39.0|  M|          ATA|     39.0|    40.0|\n",
      "|49.0|  M|          ASY|     49.0|    50.0|\n",
      "|42.0|  F|          NAP|     42.0|    43.0|\n",
      "|54.0|  F|          ATA|     54.0|    55.0|\n",
      "|38.0|  M|          ASY|     38.0|    39.0|\n",
      "|43.0|  F|          ATA|     43.0|    44.0|\n",
      "|60.0|  M|          ASY|     60.0|    61.0|\n",
      "|36.0|  M|          ATA|     36.0|    37.0|\n",
      "+----+---+-------------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'ChestPainType', 'RestingBP', 'AgeFixed']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+\n",
      "| age|avg(RestingBP)|\n",
      "+----+--------------+\n",
      "|77.0|          77.0|\n",
      "|76.0|          76.0|\n",
      "|75.0|          75.0|\n",
      "|74.0|          74.0|\n",
      "|73.0|          73.0|\n",
      "+----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group by age\n",
    "disease_by_age = df.groupby('age').mean().select(['age','avg(RestingBP)'])\n",
    "# sort values in desnding order\n",
    "from pyspark.sql.functions import desc\n",
    "disease_by_age.orderBy(desc(\"age\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------------------+\n",
      "|min(age)|max(age)|    avg(RestingBP)|\n",
      "+--------+--------+------------------+\n",
      "|    28.0|    77.0|53.510893246187365|\n",
      "+--------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregate function\n",
    "from pyspark.sql import functions as F\n",
    "df.agg(F.min(df['age']),F.max(df['age']),F.avg(df['RestingBP'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|sex|\n",
      "+---+\n",
      "|  M|\n",
      "|  F|\n",
      "+---+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----+----+\n",
      "|older| age|\n",
      "+-----+----+\n",
      "| true|40.0|\n",
      "| true|49.0|\n",
      "+-----+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run an SQL query on the data\n",
    "df.createOrReplaceTempView(\"df\") # tell PySpark how the table will be called in the SQL query\n",
    "spark.sql(\"\"\"SELECT sex from df\"\"\").show(2)\n",
    "\n",
    "# we also choose columns using SQL sytnx, with a command that combins '.select()' and '.sql()'\n",
    "df.selectExpr(\"age >= 40 as older\", \"age\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+\n",
      "| age|  M|  F|\n",
      "+----+---+---+\n",
      "|64.0| 16|  6|\n",
      "|47.0| 15|  4|\n",
      "|58.0| 35|  7|\n",
      "+----+---+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('age').pivot('sex', (\"M\", \"F\")).count().show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "|sex|true|false|\n",
      "+---+----+-----+\n",
      "|  F| 174|   19|\n",
      "|  M| 664|   61|\n",
      "+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pivot - expensive operation\n",
    "df.selectExpr(\"age >= 40 as older\", \"age\",'sex').groupBy(\"sex\")\\\n",
    "                    .pivot(\"older\", (\"true\", \"false\")).count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
